# Virtual Reality

# Lesson 1: introduction to VR and AR

XR consists of Virtual Reality, Mixed Reality and Augmented Reality.


- VR: A complete immersion experience that shuts out the physical world
- MR: Combines elements of both AR and VR, real-world and digital objects interact.
- AR: Adds digital elements to a live view often by using the camera on a smartphone.


![Virtual Reality](https://www.techdrum.ng/wp-content/uploads/2018/03/vr-future-jobs.jpg)
![Mixed Reality](https://blog.equinix.com/wp-content/uploads/2018/03/virtual-reality-vr.jpg)
![Augmented Reality](https://cdn.datafloq.com/cache/blog_pictures/878x531/three-industries-benefit-augmented-reality.jpg)




## 360/VR cameras
![360-degree camera](https://hniesfp.imgix.net/8/images/detailed/84/samsung_gear360_2017_1.jpg?fit=fill&bg=0FFF&w=1500&h=1000&auto=format,compress)
![3D camera](https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2014/11/Beyond_View_White_1.jpg)


**360-degree camera:** a view in every direction is recorded at the same time, shot using an omnidirectional camera or a collection of cameras.
**3D-camera:** enables the perception of depth in images to replicate three dimensions as experienced through human binocular vision



# Research
## Storytelling in VR

Virtual Reality frees it up and allows it to be immersive. The first words of most first viewers of virtual reality when experiencing the media usually are: “It feels like being there”. Reactions to the images are much more emotional. People get sick with fast motion videos, and horror stories filmed in 360 are more, well, horrific. Immersive photos of places and of memories trigger deeper reactions than when seen in a normal screen.

The way to navigate a story in Virtual Reality is more like when kids run around the playground. They explore their surroundings discovering at their pace the puzzles of the story that is like a hide and seek game.


![](https://cdn-images-1.medium.com/max/1000/0*2zH414Q4nWLo7zs0.jpg)


The story creator can choose to add either static or interactive elements within a 360 degree immersive environment. Static elements can be used to explain details of the environment. Interactive elements are like hyperlinks that transport the user to a new environment, called “Teleporting”.

**Memories**
One of the remarkable features of immersive VR is that it creates memories for the viewer that can be as real as an actual experience. “In the very best examples of immersive storytelling, a few days later, the user or the viewer can actually remember that story as if it had actually occurred to them”.

**Production**
A big challenge that people need to think about is the pre-production phase. You have to figure out, in advance, how you’re going to move the user through the story, and how you’re going to deal with the fact that these 360-degree cameras see everything, so there’s nowhere to put lights and crew.

**Main takeaways**

- Storytelling in Virtual Reality must not be linear
- The user should decide which parts of the story to explore
- Reduce the effort of the viewer by moving her to the next part of the story automatically (Slideshow)
- Limit the number of inflection points and make easy to understand what will happen if that path is taken
- Provide a clear signal that the story has reached the end
- Allow the user to “bail out” of the story at any time.


***Sources:***
***[Adobe Communications Team. (2018, September 1). Immersive Virtual Reality Creates a New Currency in Storytelling. Retrieved September 16, 2018, from https://theblog.adobe.com/immersive-virtual-reality-creates-new-currency-storytelling/]*
*[Damiani, J., & Southard, D. (2017, October 2). Writing for VR: The Definitive Guide to VR Storytelling. Retrieved September 16, 2018, from https://vrscout.com/news/writing-vr-definitive-guide-vr-storytelling/]*
*[Rodriguez, M. (2016, December 26). Storytelling in virtual reality. Retrieved September 16, 2018, from https://hackernoon.com/storytelling-in-virtual-reality-cf8efc5e78f1]*



## Locomotion in VR

VR adds some new ways of locomotion/transportation as opposed to the ‘classic’ video games.

**Classic controls:**

- Keyboard (WASD- of arrow keys)
- Mouse
- Gamepads (standard control scheme)

**VR controls:**

- **Two-thumbstick artificial locomotion method**

Problem: triggers motion sickness. Solution below.


- **Comfort mode (seated)**

Linear motion with a joystick triggers sickness in some people, but short incremental adjustments don’t. Comfort Mode splits your rotation into short, instantaneous jumps instead of a continuous spin, which is surprisingly effective. For whatever reason, your brain accepts that your surroundings change in the blink of an eye, but it can’t reason with spinning scenery when you’re stationary.


- **Teleportation**

Allows you to teleport across the map so you don’t have to rely on artificial forward movement. It also lets you pinpoint an area within view that you’d like to move to and jump to it instantly.


- **Warp Speed**

A bit like teleportation;  sort of like an adrenaline rush where you become hyper-vigilant and sprint to safety.


- **From Host To Host**

 You jump across the map by switching from host to host.
 

- **ArmSwinger**

You swing your arms back and forth. Squeeze the grips on each controller and swing your arms at your sides as if you were walking at a brisk pace to move. The faster you swing the controllers, the faster you move in the virtual world.


- **Dynamic FOV Reduction**
![](https://img.purch.com/rc/600x450/aHR0cDovL21lZGlhLmJlc3RvZm1pY3JvLmNvbS9RL04vNzQwOTc1L29yaWdpbmFsL2R5bmFtaWMtZm92LkpQRw==)


Whenever users are in motion, the FOV begins to close in around them. This effect reduces the amount of detail they notice as they move through a virtual environment, in turn reducing the potential triggers for vestibular mismatch.
Dynamically reducing the field of view while moving in VR dramatically reduced the likelihood of triggering motion sickness.



- **On-Rails Locomotion**
****
Your avatar’s body gets strapped into the mech, which gives you one-to-one control of the mech’s arms and makes it feel like you are one with the towering machine. But you never get to walk around as the mech.


- **Physical Movement- Planted**

You must duck behind cover and keep your head down if you wish to survive. The gameplay is restricted to a single room-scale area.


- **Teleport- Projected Avatar**

You get to see a virtual avatar of yourself moving through the area before you decide where you wish to go next.


- **Head-Bobbing Locomotion**

You can activate the motion by bobbing your head up and down, or by running in place.


***Sources:***
***[Carbotte, K. (2016, December 1). VR Locomotion Is A Problem That Has Many Half-Solutions. Retrieved September 15, 2018, from https://www.tomshardware.com/news/vr-locomotion-developer-solution-roundup,33108.html]*
*[Carbotte, K. (2018, March 10). Do the Locomotion: The 19 Ways You Walk and Run in VR Games. Retrieved September 15, 2018, from https://www.tomshardware.com/picturestory/807-virtual-reality-games-locomotion-methods.html#s4]*



## Motion sickness

Lateral movement with a thumbstick or a keyboard can trigger motion sickness in a lot of people. Your inner ear controls your sense of balance and spatial awareness (vestibular system), if what your inner ear perceives is different from what your eyes perceive (vestibular mismatch) you can lose your balance or get dizzy. 



## Interfaces in VR

VR applications are made up of two types of components: environments and interfaces.

You can think of an **environment** as the world that you enter when you put on a VR headset — the virtual planet you find yourself on, or the view from the [rollercoaster](https://www.youtube.com/watch?v=l3V8zeSljUU) that you’re riding.
 
An **interface** is the set of elements that users interact with to navigate an environment and control their experience. All VR apps can be positioned along two axes according to the complexity of these two components.


![](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/3675371c-502e-40d3-bf09-e42dded374bc/16-cross-graph-preview-opt.png)
![](https://cloud.netlifyusercontent.com/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/0c7af5b3-af09-4363-a253-38ff7f45cb14/6-dual-canvas-preview-opt.jpg)

- **Non-diegetic UI type of interface**

In non-VR projects, UI is frequently overlaid on top of the screen to show things like health, score, and so on as what we often refer to as a HUD (Heads Up Display). This is known as non-diegetic UI - it doesn’t exist within the world, but makes sense for the player in the context of viewing the game. → non-diegitic sound [e.g. background music]. The overlay usually doesn’t work well.


- **Spatial UI type of interface**

We generally need to position our UI within the environment itself using *World Space* Canvas render mode. This will allow our eyes to focus on the UI.

****
- **Diegetic U**I

An alternative to Spatial UI is to have elements in the environment itself display information to the user. This could be a working clock on the wall, a TV, computer display, mobile phone, or a holographic display on a futuristic gun. This is known as Diegetic UI.

**Examples:**

![Main Menu](https://unity3d.com/sites/default/files/learn/9_mainmenu.png)
![Flyer Intro](https://unity3d.com/sites/default/files/learn/10_flyer-intro-ui.png)

![Flyer UI Facing Camera](https://unity3d.com/sites/default/files/learn/11_flyer-ui-facing_camera.png)
![Maze Intro](https://unity3d.com/sites/default/files/learn/12_maze-intro.png)



![Target Gallery Intro](https://unity3d.com/sites/default/files/learn/14_target_gallery_intro.png)
![Diegetic Gun](https://unity3d.com/sites/default/files/learn/15_diegetic-gun.png)


**Typography**
When it comes to design, one can never get away from typography, and when it comes to typography in space, virtual or real — it’s all about the readability and communication.

**Targetting**
Users might gaze naturally in the center after invoking a thumbnail. Putting your targets out of the natural gaze position will prevent accidental clicks.

**Mock it up**
Design comps are great, but you really need to see it in a headset to get an idea of what you’re designing.

**Feedback**
Give your users some feedback when they’ve hovered over something interactive. The more the better, because a VR environment can be pretty distracting.

***Sources:***
*[Applebee, S., & Deruette, A. (2017, January 6). Getting Started With VR Interface Design. Retrieved September 16, 2018, from https://www.smashingmagazine.com/2017/02/getting-started-with-vr-interface-design/]*
*[Hsu, J. (2016, August 12). 4 Things I learned Designing User Interfaces for VR at Disney.. Retrieved September 16, 2018, from https://medium.com/startup-grind/4-things-i-learned-designing-user-interfaces-for-vr-cc08cac9e7ec]*
*[Unity. (n.d.-c). User Interfaces for VR. Retrieved September 16, 2018, from https://unity3d.com/learn/tutorials/topics/virtual-reality/user-interfaces-vr]*


# XR Experiences

**HoloLens**
Tried it out; wasn't able to play anything though. The device didn’t connect to the WiFi so my experience basically existed of trying to connect for about 6 times. I do like how the AR allows you to focus only on the overlay too, makes me curious about how other applications work.

Only being able to select things with the single index finger didn’t really work for me though as it tired my hands. A. LOT.

**Vive Pro**
Tried the 3D painting, 

**Oculus Rift**
Tried the Star Trek Bridge Control game. You’d really get sucked in but the game was a bit messy due to not following the tutorial beforehand. Liked how the interaction was between the players, although the unclear voices were something that added to the mess too.

Also tried a shooter game; just hitting targets in a saloon with a revolver.

**Gear VR**
Some shooter game for a short amount of time.


# Concepts

What really struck me in almost every game, was the lack of hints when you didn’t really know what to do anymore. E.G. when my revolver’s chambers were empty, I just stood there for the remaining 2 minutes, Only after asking classmates whom have followed the tutorial, I learned that you would have to shake your gun to reload.

That’s why my first challenge will be: **in what ways can the user be informed of possible actions at the exact moment, and when would those occur?**

The second thing that fascinated me, was multiplayer-mode and interacting with either real-life others or in-game characters. ST Bridge Control felt like a big chat room and it really helped to get you all-in the game. I’m curious about the ways of person-to-person interaction, so my second challenge will be: **In what ways can the user interact/conversate with other (real-life)characters or players? → expandable to a prototype where you’ll have to follow a McDonalds-like cashier training. → in particular, NPC**

The third remarkable thing while testing was how tired my arms, hands or fingers got after a while of using a device. Whilst using the HoloLens, my finger got reeeaally tired. For casual use it’d be alright and more natural, but for longer use it’d really be too annoying. When I tried other devices (with hand grips!) it wasn’t tiring at all and I wonder for how long I could use one before getting sore muscles. My third challenge is: **what kinds of control/locomotion causes the most or least sore muscles, in what time span?**

Arkham VR 

Bedenk wat de essentie is van jouw concept. Stel een hypothese op: wat wil je te weten komen met je prototype? 


# Final concept

What I’d like to get to know with my prototype is how one another could interact naturally with another (NP)character. So, my research question will be: **In what ways can the user interact/conversate with non-playable characters? (+in an immersive way)**


## Subquestions:
- In what ways do people already interact face-to-face with each other in real life?
- What kind of interaction with NPC's is already possible in VR? Gestures, speech recognition?
- How are conversations with NPC’s usually initiated in-game?

**In what ways do people already interact face-to-face with each other in real life?**
There’s two kinds of communication: verbal and non-verbal.

**Verbal**: entails the use of words in delivering the intended message. The two major forms of verbal communication include written and oral communication.

**Non-verbal**: entails communicating by sending and receiving wordless messages. These messages usually reinforce verbal communication, but they can also convey thoughts and feelings on their own.

Examples of all:

- Talking
- Gestures
- Nodding/shaking of head
- Pointing out
- Sign language
- Sounds

→ https://medium.com/@justthisguy/immersive-conversation-through-gamification-899bd0b5e7c4

Anyhow, most suitable would be talking, gestures, nodding/shaking/pointing.

***Sources:***
*[Nayab, N. (2017, August 3). Three different types of communication. Retrieved from https://www.brighthubpm.com/methods-strategies/79297-comparing-various-forms-of-communication/]*

******What kind of interaction with NPC's is already possible in VR? Gestures, speech recognition?**

![Suggestion of speech](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537751351684_image.png)
![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537751519258_image.png)

- First, a few suggestions of what words/sentences to say pop up quickly. When you pronounce/choose one of them, ‘your’ character repeats your sayings in a correct sentence back to the NPC, making it sound like a real conversation.


![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537752103826_image.png)


The answers to the NPC’s questions are visible on-screen and you’ll have to tap them to select. Not immersive at all.


![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537752932437_image.png)

- It seems to be that you have a few choices of key-words and have to pronounce one of them to get your character to speak. You have limited time in answering, just like in real life.



![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537753121133_image.png)

- You get a set of [things] to choose from, not even in a real sentence. Your character does nog reply in any sentence at all, too.
- ..
![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537798253305_image.png)



**How are conversations with NPC’s usually initiated in-game?**

- By saying 'Hello’
![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537751891110_image.png)
![](https://d2mxuefqeaa7sj.cloudfront.net/s_4208D1B3AAF72B8CCEB09EACC9F9111E23E2AF90C7E191779E6B9AA63309719D_1537751973292_image.png)

- Poking the NPC could be possible, although that's not the case in this game. Here, you wave at them to start a conversation/interaction.


## Hardware needed
- Gloves for gestures
- Microphone
- Headphones attached


## Prototype lo-fi

Storyboard concept

- walking up to a npc
- waving, saying hi, poking, whatevs is convenient (e.g. only the back visible, go poke)
- have the npc speak first
- have the set of answers displayed
- use those keywords in a sentence
- have the other character repeat a bit of yours (e.g. ‘ah, so you’re looking for the stairs? hmm [..]
- have that character reply their own answer

Storyboard prototype
instead of speach, poking of the suggestion, boxes

- walking up
- poking
- have the npc talk
- get those keyword boxes
- tap one
- have the npc reply with part of that keyword
- have the npc reply their own

***Sources:***
*[Gooboberti. (2017, December 21). Ghoul NPC Interaction - Fallout 4 VR | Oculus Rift [Video file]. Retrieved September 20, 2018, from https://www.youtube.com/watch?v=NDLPMO2Y2i4]*
*[MasterGamingVR. (2017, June 30). Orbus VR MMORPG Alpha weekend 6 - Quests and NPC interactions [Video file]. Retrieved September 20, 2018, from https://www.youtube.com/watch?v=XeVi44iajN0]*
*[AntiAnti. (2017, January 28). VR Dialog System - Step 3 [Video file]. Retrieved September 20, 2018, from https://www.youtube.com/watch?v=h9sBXvwDdbI]*


https://www.youtube.com/watch?v=03ozC8m5slQ&


[https://youtu.be/03ozC8m5slQ](https://youtu.be/03ozC8m5slQ)

https://www.youtube.com/watch?v=_nRzoTzeyxU&


[https://youtu.be/_nRzoTzeyxU](https://youtu.be/_nRzoTzeyxU)

https://www.youtube.com/watch?v=xlnXWY82NN4&


[https://youtu.be/xlnXWY82NN4](https://youtu.be/xlnXWY82NN4)
https://www.pcgamer.com/speak-your-dialogue-lines-in-skyrim-vr-with-this-voice-recognition-mod/

https://www.youtube.com/watch?v=IjFw4eawo6E&


[https://youtu.be/IjFw4eawo6E](https://youtu.be/IjFw4eawo6E)



→> wat mist er nog bij de skyrim mod?
→ dat je niet alleen kan kiezen uit volledige zinnen, maar uit keywords om niet voor te kauwen enzo.

